{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d959525-0a9b-499b-948d-d107c96c0130",
   "metadata": {},
   "source": [
    "(contextual)=\n",
    "# Contextual terminal symbols\n",
    "\n",
    "Now that we have attributes, a follow-up token can be recognized by the parser, and yet\n",
    "raise an error during the evaluation of the attribute expression.\n",
    "\n",
    "I believe we have reached a point where the classic features of parsers (synthesized and inherited attributes) \n",
    "are not enough for guided generation. We need to have not only the list of types of token which\n",
    "can follow in a sentence, but also which values are admissible.\n",
    "\n",
    "To the best of my knowledge, this is a new kind of feature. Let's call them contextual terminal symbols: terminal\n",
    "symbol which matching value is depending on the context of execution.\n",
    "\n",
    "## Regex attributes for terminal symbols\n",
    "\n",
    "So we introduce (yet) another kind of attributes: python expression attached to terminal symbols.\n",
    "\n",
    "Those expressions are expected to return a regex, and they are evaluated when a lookahead on that symbol is checked.\n",
    "The value of the next token is then matched against that regex in order to\n",
    "decide if the corresponding transition is admissible or not.\n",
    "\n",
    "Let's see on a mock example what it means. We define the grammar for a language of `let ... in {...}` statements with two rules:\n",
    "* variable shadowing in nested declarations is allowed; so `let x, y in {let y, z in {...}}` is correct\n",
    "* the same variable cannot be declared multiple times in the same `let` statement; so `let x, x in {...}` is invalid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43ebc97a-de5e-4245-b420-9cd1bf20ac3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lark import Lark\n",
    "\n",
    "nested_vars_grammar = \"\"\"\n",
    "%import common.NUMBER\n",
    "%import common.CNAME\n",
    "%import common.WS\n",
    "%ignore WS\n",
    "\n",
    "%python_header {{\n",
    "from collections import Counter\n",
    "\n",
    "def init_ctx(global_vars): \n",
    "    from collections import defaultdict\n",
    "    global_vars.ctx = defaultdict(lambda: 0)\n",
    "\n",
    "def add_vars(global_vars, var_list):\n",
    "    global_vars.ctx.update([(k, global_vars.ctx[k] + 1) for k in var_list])\n",
    "    \n",
    "def remove_vars(global_vars, var_list):\n",
    "    global_vars.ctx.update([(k, global_vars.ctx[k] -1) for k in var_list])\n",
    "   \n",
    "def exclude_vars(var_list):\n",
    "    if len(var_list) > 0:\n",
    "        return \"(?!(\" + '|'.join([w + '$' for w in var_list]) + \"))\"\n",
    "    else:\n",
    "        return \"(.*?)\"\n",
    "}}\n",
    "\n",
    "start: expr{{ init_ctx(GLOBAL) }} _expr\n",
    "\n",
    "expr : \"let\" declar_var{{ [] }} \"in\" \"{\" expr{{ add_vars(GLOBAL, syn[2]) }} \"}\" _expr{{ remove_vars(GLOBAL, syn[2]) }}\n",
    "| \"some_expr\" \"(\" args \")\" _expr\n",
    "\n",
    "_expr: \n",
    "| \";\" expr\n",
    "\n",
    "declar_var: CNAME{{ exclude_vars(inh) }} _declar_var{{ [syn[1], *inh] }}      {{ [syn[1], *syn[2]] }}\n",
    "\n",
    "_declar_var: \",\" declar_var{{ inh }}      {{ syn[2] }}\n",
    "|    {{ inh }}\n",
    "\n",
    "args: atom _args\n",
    "\n",
    "_args:\n",
    "| \",\" args\n",
    "\n",
    "atom: NUMBER\n",
    "| CNAME{{ '|'.join([k + '$' for k,v in GLOBAL.ctx.items() if v > 0]) }}\n",
    "\n",
    "\"\"\"\n",
    "parser = Lark(nested_vars_grammar, parser=\"lalr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee785513-a34a-48dd-b65b-eed1fa33e64e",
   "metadata": {},
   "source": [
    "The point of interest here are the attributes attached to the `CNAME` terminal symbol in the rules for `atom` and `declar_var`:\n",
    "* in `atom`, we are inside the core an expression, the attribute `{{ '|'.join([k + '$' for k,v in GLOBAL.ctx.items() if v > 0]) }}` is evaluated to the regex matching all the variable names declared in that context\n",
    "* in `declar_var`, we are inside a `let` declaration, the attribute `{{ exclude_vars(inh) }}` is evaluated to a regex matching *anything but* the variables already declared in the same `let`\n",
    "\n",
    "The `accepts()` method of the interactive parser has been modified to return these regex with the next admissible tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b4ef92b-9ed2-4ca1-adbc-c793bc865fe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Token('NUMBER', '(.*?)'), Token('CNAME', 'x$|y$|w$')}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def next_token(expr, parser):\n",
    "    interactive_parser = parser.parse_interactive(start=\"start\")\n",
    "    for t in parser.lex(expr):\n",
    "        interactive_parser.feed_token(t)\n",
    "    return interactive_parser.accepts()\n",
    "\n",
    "next_token(\"\"\"\n",
    "        let x, y in { some_expr(x,y); let w in { some_expr(\n",
    "\"\"\", parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b777024-f0b6-415e-add8-44a79286d238",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Token('NUMBER', '(.*?)'), Token('CNAME', 'x$|y$|z$')}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_token(\"\"\"\n",
    "        let x, y in { some_expr(x,y); let w in { some_expr(w) }; let y,z in { some_expr(\n",
    "\"\"\", parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2fc18fd-0266-490c-9a04-57a3c0c9b549",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Token('CNAME', '(?!(w$|v$|z$))')}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_token(\"\"\"\n",
    "        let x, y in { some_expr(x,y); let y,z in { some_expr(13) }; let z, v, w,\n",
    "\"\"\", parser)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8b6d8863-0e5f-4cf5-934d-9dfcaae1eec6",
   "metadata": {},
   "source": [
    "So the parser not only tells us what are the next types of token accepted to continue the sentence, but also which values\n",
    "are valid.\n",
    "\n",
    "An important note: these regex don't affect the lexer; the values of the token are matched against the regex\n",
    "*after* they have passed the lexer.\n",
    "\n",
    "## Implementation \n",
    "\n",
    "### Building the parser\n",
    "\n",
    "The contextual terminal symbols are treated like regular terminal symbol by the builder.\n",
    "\n",
    "This could lead to mistakes when the same token type appears as a lookahead in multiple items of a `LROItemSet`, but with possibly \n",
    "different contextual expression.\n",
    "\n",
    "Concretely we need to detect grammars like\n",
    "```\n",
    "start: CNAME{{ 'foo' }} \"foo\"\n",
    "| CNAME{{ 'bar' }} \"bar\"\n",
    "```\n",
    "\n",
    "The parser will raise an error (a Shift/Shift conflict of some sort) when during the computation of an `LR0ItemSet`\n",
    "the same symbol name with an AST expression appears as next symbol in the progression of multiple rules.\n",
    "\n",
    "### Contextual lookahead\n",
    "\n",
    "Internally the core of the parser is a dictionary `dict[State, dict[Token, Tuple]]`:\n",
    "* in a given state, it return a dictionary of transitions `dict[Token, Tuple]]`\n",
    "* the transition table matches a lookahead token with the next steps of the parser: a `Tuple` of a new state, a Reduce or Shift action\n",
    "\n",
    "This is where the AST expression of the contextual terminal symbol is inserted: it is added to the `Tuple` in the transitions tables (during the compilation of the parser).\n",
    "\n",
    "The transitions dictionaries of each state are wrapped into an object \n",
    "which will capture the consulting of the transitions. When it is accessed, it will evaluates the AST expression\n",
    "and return a `KeyError` if the token don't match the regex pattern.\n",
    "\n",
    "The `accepts()` method is simply returning those (non empty) regex with the token type."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "guiding-typed-lang",
   "language": "python",
   "name": "guiding-typed-lang"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
