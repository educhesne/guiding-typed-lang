{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85450492-acb8-49bb-9849-3256faaef495",
   "metadata": {},
   "source": [
    "(haskell)=\n",
    "# Generating typed Haskell terms\n",
    "\n",
    "We are ready to define a grammar for typed functional terms in Haskell, and see how to generate them with outlines.\n",
    "\n",
    "## The target language\n",
    "\n",
    "The target language is only a fragment of Haskell, limited to:\n",
    "* `\\ ... -> ...` lambda abstraction\n",
    "* `t u` application\n",
    "* `(t,u)` pair\n",
    "* `fst`, `snd` projections (e.g. `fst (t,u)` evaluates to `t`)\n",
    "\n",
    "The pair construction will be written in infix notation: `(,) t u` instead of `(t,u)`.\n",
    "\n",
    "Applications are associative to the left: `t u v` is `(t u) v`.\n",
    "\n",
    "For instance the third iterator is `\\ f u -> (f (f (f u)))` and we can call on the interactive interpreter to see its inferred type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2dc94910-b484-490b-8a20-ff6c67fb208f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\ f u -> (f (f (f u))) :: (t -> t) -> t -> t\n"
     ]
    }
   ],
   "source": [
    "!ghci -v0 <<< ':t    \\ f u -> (f (f (f u)))'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b58b0c6-28c3-41d4-a3cf-9191bc982e8d",
   "metadata": {},
   "source": [
    "## Type inference\n",
    "\n",
    "These terms have simple types made of type variables, arrow types `t1 -> t2` and product types `(t1,t1)`.\n",
    "\n",
    "The term variables are declared without a type hint. The goal of type inference is to assign types to \n",
    "term variables so that the whole term is typable.\n",
    "\n",
    "It is essentially an unification process: when facing an application `t u`, with `t` of type `a -> b` and `u` of type `a'`, try to\n",
    "unify `a` and `a'` and reify all the other types accordingly.\n",
    "\n",
    "This explains why it is not possible to guide the generation of typed terms in that syntax: in a context where `t` is given a type `a -> b`, trying to complete an term ending with an application `t _` means trying to generate on demand a term whose type matches `a`.\n",
    "\n",
    "## Postfix notation\n",
    "\n",
    "This issue does not occur if we decide to transform the language and to use a postfix notation for applications, that is\n",
    "to say if we write the applications `t u App` instead.\n",
    "\n",
    "In that case, when the generation reaches the point of completing a sequence `t u _`, it decides wether to complete with `App`, \n",
    "only if the type matches, or with `(,)`, which doesn't have a type constraint.\n",
    "\n",
    "The postfix language is not recognized by Haskell, however moving back and forth between the orginal language \n",
    "and the postfix form is a simple syntactic tree operation.\n",
    "\n",
    "## The grammars\n",
    "\n",
    "The functions called in the attributes to manage declaration contexts and type inference are relegated in a [companion library](https://github.com/educhesne/guiding-typed-lang/tree/main/simple_types). The synthesized attributes are used to compute the inferred types.\n",
    "\n",
    "The details of type inference is not the focus of this document; it suffices to know that the function `ctx_app`\n",
    "called in the attribute of the derivation `app: app term` may raise a `TypeError` when the type unification process fails.\n",
    "\n",
    "### For typed terms\n",
    "\n",
    "First the grammar to parse typed Haskell terms; it cannot be used for guided generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f42b4e6-49b8-41fb-b158-f19140ea8004",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lark import Lark\n",
    "\n",
    "typed_lambda_grammar = \"\"\"\n",
    "%import common.CNAME\n",
    "%import common.WS_INLINE\n",
    "%ignore WS_INLINE\n",
    "\n",
    "%python_header {{\n",
    "from simple_types.attribute_utils import *\n",
    "}}\n",
    "\n",
    "?start: _start{{ init_ctx(GLOBAL) }}         {{ syn[1] }}\n",
    "\n",
    "_start: lambda                {{ syn[1] }}\n",
    "| app                         {{ syn[1] }}\n",
    "\n",
    "app: app term                       {{ ctx_app(syn[1], syn[2], GLOBAL) }}  -> app\n",
    "| term                              {{ syn[1] }}       ->   term\n",
    "\n",
    "term: CNAME{{ ctx_vars(GLOBAL) }}   {{ GLOBAL.ctx[syn[1]] }}  -> term\n",
    "| \"(\" lambda \")\"                    {{ syn[2] }}              -> term\n",
    "| \"(\" app \")\"                       {{ syn[2] }}              -> term\n",
    "| PAIR                              {{ fresh_pair_types(GLOBAL)[0] }}     -> term\n",
    "| FST                               {{ fresh_pair_types(GLOBAL)[1] }}     -> term\n",
    "| SND                               {{ fresh_pair_types(GLOBAL)[2] }}     -> term\n",
    "\n",
    "lambda: LAMBDA vars TO app{{ add_vars(GLOBAL, syn[2]) }}   {{ ctx_lambda(syn[2], syn[4], GLOBAL) }}   -> abstraction\n",
    "\n",
    "vars: CNAME{{ exclude_vars(GLOBAL, []) }} _vars{{ [syn[1]] }}      {{ syn[2] }}      -> vars\n",
    "\n",
    "_vars: {{ inh }}\n",
    "| CNAME{{ exclude_vars(GLOBAL, inh) }}  _vars{{ [*inh, syn[1]] }}    {{ syn[2] }}\n",
    "\n",
    "LAMBDA: \"\\\\\\\\\"\n",
    "TO: \"->\"\n",
    "PAIR: \"(,)\"\n",
    "FST: \"fst\"\n",
    "SND: \"snd\"\n",
    "\"\"\"\n",
    "\n",
    "prefix_parser = Lark(typed_lambda_grammar, parser=\"lalr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4db776f-c630-4ab8-8e32-8b4a60dc4a21",
   "metadata": {},
   "source": [
    "### For typed term with postfix application\n",
    "\n",
    "Now the grammar for the terms with application in postfix form.\n",
    "\n",
    "The only difference is the rule for `app`: the application constructor `App` appears as a contextual terminal symbol. It is non-empty\n",
    "only if the types of the previous symbols are matching.\n",
    "\n",
    "Note also the alternative derivation `term term PAIR`: this one has no type condition so the generation never ends up in a deadend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f2800f2-a8f3-4a68-839a-234fafd2084e",
   "metadata": {},
   "outputs": [],
   "source": [
    "postfix_lambda_grammar = \"\"\"\n",
    "%import common.CNAME\n",
    "%import common.WS_INLINE\n",
    "%ignore WS_INLINE\n",
    "\n",
    "%python_header {{\n",
    "from simple_types.attribute_utils import *\n",
    "}}\n",
    "\n",
    "?start: _start{{ init_ctx(GLOBAL) }}         {{ syn[1] }}\n",
    "\n",
    "_start: lambda                {{ syn[1] }}\n",
    "| app                         {{ syn[1] }}\n",
    "\n",
    "app: term term APP{{ \"App$\" if ctx_is_applicable(syn[1], syn[2], GLOBAL) else \"\" }}     {{ ctx_app(syn[1], syn[2], GLOBAL) }}    -> app\n",
    "| term term PAIR                                                                        {{ ctx_pair(syn[1], syn[2], GLOBAL) }}   -> pair\n",
    "| term                                                                                  {{ syn[1] }}                             -> term\n",
    "\n",
    "term: CNAME{{ ctx_vars(GLOBAL) }}   {{ GLOBAL.ctx[syn[1]] }}  -> term\n",
    "| \"(\" lambda \")\"                    {{ syn[2] }}              -> term\n",
    "| \"(\" app \")\"                       {{ syn[2] }}              -> term\n",
    "| PAIR                              {{ fresh_pair_types(GLOBAL)[0] }}     -> term\n",
    "| FST                               {{ fresh_pair_types(GLOBAL)[1] }}     -> term\n",
    "| SND                               {{ fresh_pair_types(GLOBAL)[2] }}     -> term\n",
    "\n",
    "lambda: LAMBDA vars TO term{{ add_vars(GLOBAL, syn[2]) }}   {{ ctx_lambda(syn[2], syn[4], GLOBAL) }}   -> abstraction\n",
    "\n",
    "vars: CNAME{{ exclude_vars(GLOBAL, []) }} _vars{{ [syn[1]] }}      {{ syn[2] }}      -> vars\n",
    "\n",
    "_vars: {{ inh }}\n",
    "| CNAME{{ exclude_vars(GLOBAL, inh) }}  _vars{{ [*inh, syn[1]] }}    {{ syn[2] }}\n",
    "\n",
    "LAMBDA: \"\\\\\\\\\"\n",
    "TO: \"->\"\n",
    "PAIR: \"(,)\"\n",
    "FST: \"fst\"\n",
    "SND: \"snd\"\n",
    "APP: \"App\"\n",
    "\"\"\"\n",
    "\n",
    "postfix_parser = Lark(postfix_lambda_grammar, parser=\"lalr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9868f5c0-1170-4194-bdf3-e17fda56b436",
   "metadata": {},
   "source": [
    "## Syntactic tree transformation\n",
    "\n",
    "Lark returns the syntactic tree as a `Tree` objects and provides tools to transform them; so we define a few transformation:\n",
    "* `PrefixToPostfix()` will transform the result of the prefix parser into postfix form\n",
    "* `PostfixToPostfix()` will do the opposite transformation\n",
    "* `PrefixToTxt()` and `PostfixToTxt()` will write down those trees as terms recognized by the parsers\n",
    "\n",
    "Up to parenthesis, these operation are inverse of each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "019a9edb-7bd6-44a2-b020-cf1bb9c61c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lark.visitors import Transformer\n",
    "from lark.tree import Tree\n",
    "from lark.lexer import Token\n",
    "\n",
    "class PrefixToPostfix(Transformer):\n",
    "    def app(self, children):\n",
    "        if len(children) == 2:\n",
    "            if isinstance(children[0], Tree) and children[0].data == 'app' and len(children[0].children) == 3 and children[0].children[0] == Token('PAIR', '(,)'):\n",
    "                return Tree('pair', [children[0].children[1], children[1], Token('PAIR', '(,)')])\n",
    "            else:\n",
    "                return Tree('app', [children[0], children[1], Token('APP', 'App')])\n",
    "        elif len(children) == 1:\n",
    "            return children[0]\n",
    "        else:\n",
    "            raise SyntaxError(f\"app node expected to have 1 or 2 children, not {len(children)}\")\n",
    "\n",
    "    def term(self, children):\n",
    "        return children[0]\n",
    "\n",
    "\n",
    "class PostfixToPrefix(Transformer):\n",
    "    def app(self, children):\n",
    "        if len(children) == 3:\n",
    "            assert children[2] == Token('APP', 'App'), 'Wrong app node'\n",
    "            return Tree('app', [children[0], children[1]])\n",
    "        elif len(children) == 1:\n",
    "            return children[0]\n",
    "        else:\n",
    "            raise SyntaxError(f\"app node expected to have 1 or 3 children, not {len(children)}\")\n",
    "\n",
    "    def pair(self, children):\n",
    "        assert len(children) == 3 and children[2] == Token('PAIR', '(,)'), 'Wrong pair node'\n",
    "        return Tree('app', [Tree('app', [Token('PAIR', '(,)'), children[0]]), children[1]])\n",
    "\n",
    "    def term(self, children):\n",
    "        return children[0]\n",
    "\n",
    "\n",
    "class PostfixToTxt(Transformer):\n",
    "    def app(self, children):\n",
    "        return rf\"({children[0]} {children[1]} App)\"\n",
    "\n",
    "    def pair(self, children):\n",
    "        return rf\"({children[0]} {children[1]} (,))\"\n",
    "\n",
    "    def abstraction(self, children):\n",
    "        return rf\"(\\ {children[1]} -> {children[3]})\"\n",
    "\n",
    "    def vars(self, children):\n",
    "             return rf\"{ ' '.join([v.value for v in children])}\"\n",
    "\n",
    "    def term(self, children):\n",
    "        return children[0]\n",
    "\n",
    "\n",
    "class PrefixToTxt(Transformer):\n",
    "    def app(self, children):\n",
    "        return rf\"({children[0]}) ({children[1]})\"\n",
    "\n",
    "    def abstraction(self, children):\n",
    "        return rf\"(\\ {children[1]} -> {children[3]})\"\n",
    "\n",
    "    def vars(self, children):\n",
    "             return rf\"{ ' '.join([v.value for v in children])}\"\n",
    "\n",
    "    def term(self, children):\n",
    "        return children[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b5393e-608d-4dbd-8a23-91de864c4e8c",
   "metadata": {},
   "source": [
    "## Compute a prompt for the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74880da-0740-4e51-b9b7-5955292aaf49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write terms in Haskell using only \\ , ->, (,), fst, snd and applications, but write applications in postfix notation.\n",
      "For instance:\n",
      "Instead of (\\ x y z -> (z ((,) x y))) you should write (\\ x y z -> (z (x y (,)) App))\n",
      "Instead of (\\ n m f x -> (n (m f) x)) you should write (\\ n m f x -> ((n (m f App) App) x App))\n",
      "Write a term applying 6 times its first argument to its second argument:\n"
     ]
    }
   ],
   "source": [
    "# Pick some examples of terms to transform in postfix notation\n",
    "terms = [r\"(\\ x y z -> (z ((,) x y)))\", r\"(\\ n m f x -> (n (m f) x))\"]\n",
    "head_prompt = rf\"\"\"Write terms in Haskell using only \\ , ->, (,), fst, snd and applications, but write applications in postfix notation.\n",
    "For instance:\"\"\"\n",
    "postfix_example = lambda t: rf\"Instead of {t} you should write {(PrefixToPostfix()*PostfixToTxt()).transform(prefix_parser.parse(t)[0])}\"\n",
    "\n",
    "tail_prompt = \"Write a term applying 6 times its first argument to its second argument:\"\n",
    "prompt = \"\\n\".join([head_prompt, *[postfix_example(t) for t in terms], tail_prompt])\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db14495a-0242-4a35-a431-f46a62a0f7dc",
   "metadata": {},
   "source": [
    "## Generate a typed term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "19b62a9f-9da6-4dbd-a7ae-0b41237544c8",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7c662c50-361d-4602-9b73-6957937ec558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated term:\n",
      "\t  (\\ x y z -> (x (y (z) (,)) App)) (\\ n m f x -> ((n (m f App) App) x App)) (,) \n",
      "Generated term in prefix form:\n",
      "\t (((,)) ((\\ x y z -> (x) ((((,)) (y)) (z))))) ((\\ n m f x -> ((n) ((m) (f))) (x)))\n"
     ]
    }
   ],
   "source": [
    "import outlines\n",
    "\n",
    "model = outlines.models.transformers(\"HuggingFaceTB/SmolLM-135M\")\n",
    "generator = outlines.generate.cfg(model, postfix_lambda_grammar)\n",
    "postfix_term = generator(prompt)\n",
    "\n",
    "print(\"Generated term:\\n\\t\", postfix_term)\n",
    "prefix_term = (PostfixToPrefix()*PrefixToTxt()).transform(postfix_parser.parse(postfix_term)[0])\n",
    "print(\"Generated term in prefix form:\\n\\t\", prefix_term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7f6d3112-4789-4d89-9699-24889d508f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(((,)) ((\\ x y z -> (x) ((((,)) (y)) (z))))) ((\\ n m f x -> ((n) ((m) (f))) (x)))\n",
      "  :: (((a, b) -> t1) -> a -> b -> t1,\n",
      "      (t2 -> t3 -> t4) -> (t5 -> t2) -> t5 -> t3 -> t4)\n"
     ]
    }
   ],
   "source": [
    "!ghci -v0 <<< ':t {prefix_term}'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "notebook",
   "language": "python",
   "name": "notebook"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
